---
title: "Report template"

				
# Replication of Study A Gender Bias in the Attribution of Creativity: Archival and Experimental Evidence for the Perceived Association Between Masculinity and Creative Thinking 		
         by 		
					
###Devon Proudfoot, Aaron C. Kay, and Christy Z. Koval 
				
###(2015, Psychological Science)

Shima Salehi
salehi@stanford.edu

##Contacting the authors
I have contacted the authors and asked for exclusion policy as well as materials for the first study. SHortly, the authors replied in regard of exclusion policy and generously provided the survey of the first study on the Qualtrics platform.

##Introduction

The goal of this study was to examine whether in terms of creativity men and their works would be evaluated differently than women and their works. In other words, whether the judgement of creativity is influenced by the gender of a creator. To test this hypothesis, the authors asked participants to rate creativity of stereotypically masculine characteristics as well as stereotypically feminine characteristics. The researchers compared whether the attribution of creativity varied significantly across gendered characteristics. Furthermore, authors were interested to speculate that given there might be a gender bias for attribution of creativity, this bias could be moderated by how creativity is defined. They used two different definitions for creativity: 1. divergent thinking: thinking outside the box, 2. convergent thinking: bringing pieces together and connecting the dots. They decided on these two definitions, because these definition are aligned with agency and communality divide, which has been associated with masculinity and femininity divide. Therefore, authors pursued whether by defining creativity as a communal and more feminine traits versus. a more agent and masculine trait, they can manipulate the potential gender bias in attribution of creativity.

##Methods

###Power Analysis 
The power analysis is calculated based on two separate anova analyses the authors have conducted for each of the two creativity definition condition.The effect size of centrality difference is different tow trait types for divergent condition (dd) is 1.25 and the same effect size for the convergent condition (dc) 0.94. Therefore, for convergent condition that dc=0.94 and p-value <0.001 the post-hoc power is 0.986 ~ 0.99. For divergent condition, on the other hand, with dd= 1.25 and same p-value the post-hoc power is 0.999 =1.

###Planned Sample
As for the divergent condition the power is 1, the planned sample size at the significance level of 0.01 of  will be 20. For convergent condition with the power of 0.99, for the same significance level of 0.01, the sample size will be 28 . Therefore, in total I will need 48 participants. With this sample size, the effect size will be 0.94 for convergent group and 1.21 for divergent group.

##Materials & Procedure
	
###Study1:

“Participants were randomly assigned to one of two conditions. Participants in the divergent-thinking condition read a passage describing creativity as the ability to “think outside the box,” see the world differently than the average person does, and create things that do not conform to traditions. Participants in the convergent-thinking condition read that creativity is the ability to “connect the dots,” see the connections between disparate ideas, and create things that bring ideas together in a unique way (see the Supplemental Material for the text used for this manipulation).
						
Participants then rated, on a 9-point scale, how central 16 personality traits were to creativity, as described in the passage. Eight of the traits were stereotypically masculine-agentic (decisive, competitive, self-reliant, willing to take risks, ambitious, daring, adventurous, courageous), and 8 were stereotypically feminine-communal (sensi- tive, cooperative, understanding of others, helpful to others, sympathetic, nurturing, warm in relations with others, and supportive; cf. Prentice & Carranza, 2002). An exploratory factor analysis with varimax rotation revealed a two-factor structure. The 8 masculine-agentic traits loaded onto one factor, so ratings of these traits were combined (α = .88). The 8 feminine-communal traits loaded onto the other factor, so ratings of these traits were combined (α = .92).”



##Analysis Plan

Same as the authors of the original paper, we are going to conduct “a mixed-model ANOVA with condition as the between-subjects factor and trait type as the within-subjects factor”. After that we will conduct two separate ANOVA's for each of the creativity definitions to estimate the effect size of the trait type within each condition. Furthermore, for each group of gendered characteristics, we will compare the average creativity score across conditions. These are the confirmatory analyses. Besides that we will conduct a regression analysis to included all the other variables in rating a centrality of the traits for the creativity. Same as the authors, we are collecting data on age, gender, education, ethnicity, political orientation and income.

Furthermore, I have included a question about the definition of the creativity as well as the purpose of the study to use as a manipulation check for participants' engagement.

##Differences from Original Study
There is no main planned difference from the original study. There are two minor differences: first, according to the power analysis the sample size will be smaller ; second, instead of showing all the traits in one table the trait will be shown sequentially one at the time.

##Actual Sample
In the original study, eighty participants (49% female, U.S. residents) were recruited from Amazon Mechanical Turk (see Table S1 in the Supplemental Material for additional demographic information). Demographic variables did not moderate the results. 


Differences from pre-data collection methods plan
None.

##Pilot Samples
I have conducted a sample survey on the Mturk sandbox, and collected data from four pilot participants. Currently, I am working on extracting data from json format to data frame. I have issues with rectangular data frame that I need to check with instructors to address it. 


##Results

###Data preparation
Turning one json file per participants to one collective data frame with the variables of interest: rating of different traits, condition, gender, age, education, ethnicity, political orientation and income.
#### Loading Libraries
```{r loading library and fuction}
rm(list=ls())
library(tidyr)
library(dplyr)
library(ggplot2)
library(langcog) 
library(rjson)
library(tidyjson)
library(car)
library(effsize)
library(compute.es)
library(lme4)
library(lsr)

#functions for se and CI
sem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}
ci95 <- function(x) {sem(x) * 1.96}
```

####Transforming data from JSON format to dataframe
```{r reading data from JSON files to dataframe}
path <- "~/Documents/Git/salehiProject/mturk/"
files <- dir(paste0(path,"sandbox-results/"), 
             pattern = "*.json")
d.raw <- data.frame()
for (f in files) {
  jf <- paste0(path, "sandbox-results/",f)
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  id <- data.frame(workerid = jd$WorkerId, 
                   trial_number_block=    as.factor(jd$answers$data$trial_number_block),
                   rating = as.numeric(jd$answers$data$rating),
                   gender = jd$answers$data$gender,
                   age = jd$answers$data$age,
                    sentence = jd$answers$data$sentence,
                    definition = jd$answers$data$definition,
                    political = jd$answers$data$political,
                    condition = as.factor(jd$answers$data$condition),
                    homelang = jd$answers$data$homelang,
                    income = jd$answers$data$income,
                    education = jd$answers$data$education,
                    ethnicity = jd$answers$data$ethnicity)

  d.raw <- bind_rows(d.raw, id)
}

# Number of participants
length(unique(d.raw$workerid))
```

####Categorizing Traits into Masculine and Feminine
```{r trait type variable}
#creating a bolean varible for traits which are masculine vs. feminine ones
d.raw $trait <- d.raw $ sentence =='Decisive' | d.raw $ sentence =='Competitive'| d.raw $ sentence =='Self-reliant' | d.raw $ sentence =='Willing to take risks' | d.raw $ sentence =='Ambitious'| d.raw $ sentence =='Daring' | d.raw $ sentence =='Adventurous' | d.raw $ sentence =='Courageous'

#creating a varible with masculine and feminine labels rather than True and False
d.raw $traitType <- ifelse(d.raw $trait == TRUE, "Masculine", "Feminine")

#checking if relabling work properly without mislabeling
table(d.raw $traitType,d.raw $trait )
table(d.raw$traitType, d.raw$sentence)
```


####Formating variables in data frame
```{r reformatting data}
##trait type
d.raw $traitType <- as.factor(d.raw $traitType)
##condition
d.raw $condition <- as.factor(d.raw $condition)
##gender
d.raw $gender <- as.factor (d.raw $gender)

##
d.raw$ageL <- as.numeric(factor(d.raw $age , levels=c("0-17","18-24", "25-34","35-44","45-64","&gt;65")))
d.raw $ageF <- as.factor (d.raw $age)

##education
#definiing ordinal variable both linear and caregorical
d.raw$educationL <- as.numeric(factor(d.raw $education , levels=c("someMiddleSchool" ,
          "someHighSchool", "highSchoolDrad","someCollege","collegeGraduate","someGrad","Grad")))
d.raw $educationF <- as.factor (d.raw $education)

##ethnicity
d.raw $ethnicityF <- as.factor(d.raw$ethnicity)
#definiing ordinal variable both linear and caregorical

##income
#definiing ordinal variable both linear and caregorical
d.raw$incomeL <- as.numeric(factor(d.raw $income , levels=c("LessThan15000" , "15000-24999", "25000-34999","35000-49999","50000-74999","75000-99999","100000-149999","150000-199999","morethan200000")))
d.raw $incomeF <- as.factor (d.raw $income)

##political orientation
#definiing ordinal variable both linear and caregorical
d.raw$politicalL <- as.numeric(d.raw $political)
d.raw $politicaF <- as.factor (d.raw $political)

```

Furthermore, I will code the two manipulation check variables: definition of creativity, and the aim of the study on the binary scale. For definition, I will code whether a participant's definition is aligned with the definition given in her condition. For the aim variable, there will be two levels: first, "no guess" meaning that the participant's guess about the purpose of the study is at most about creativity; second, level is "close guess", when participants go beyond creativity and anticipated the study is looking at the variation of creativity across traits.

#### Manipulation check coding
```{r manipulation check}
##1. definition test
#if the participants' definition of creativit is aligned with the definition they are given in the condition. It has three levels: NA if they do not answer the question; 'aligned' if the their definition is aligned with the given defintion; 'not aligned' if their definition is not aligned with the given definition
d.raw$definition.test[d.raw$workerid=='A1AL6BBWFSGZKI'] <- NA
d.raw$definition.test[d.raw$workerid=='A35360IU4D4R7L'] <- "aligned"
d.raw$definition.test[d.raw$workerid=='A1CBWFLUD10F23'] <- NA
d.raw$definition.test[d.raw$workerid=='ALB9E1HP4FVN3'] <- "aligned"

##2. experiment test
#participants' guess about the goal of the study goes beyond creativity and mentioned more specific goal about the attribution of creativity to different traits
d.raw$expaim[d.raw$workerid=='A1AL6BBWFSGZKI'] <- "noGuess"
d.raw$expaim[d.raw$workerid=='A35360IU4D4R7L'] <- "closeGuess"
d.raw$expaim[d.raw$workerid=='A1CBWFLUD10F23'] <- NA
d.raw$expaim[d.raw$workerid=='ALB9E1HP4FVN3'] <- "closeGuess"

```

Given the few number of participants, it is difficult to sue this manipulation check to detect. However, for more number of participants I hypothesized the participants with close guess about the goal of the experiments or the one whose definitions are aligned with the definition of the activity might show the condition effect more.

####Histogram of ratings across conditions and trait types
```{r histograms}
#rating vs. condition and traits
qplot(rating, data = d.raw, binwidth= 1, fill= traitType, facets = traitType ~ condition, geom = "histogram") +  scale_fill_manual(values=c("#FF6633", "#33CCCC")) +xlim(c(1,10))

#rating vs. condition and definition.test
#qplot(rating, data = d.raw, binwidth= 1, fill= traitType, facets = definitionTest ~ condition, geom = "histogram") +  scale_fill_manual(values=c("#FF6633", "#33CCCC")) +xlim(c(1,10))

#rating vs. condition and definition.test
#qplot(rating, data = d.raw, binwidth= 1, fill= traitType, facets = aimTest ~ condition, geom = "histogram") +  scale_fill_manual(values=c("#FF6633", "#33CCCC")) +xlim(c(1,10))

```

#### ggplot with geompoint

```{r}
ggplot(d.raw, aes(x = condition, y = rating, col = traitType)) + 
  geom_jitter(width=0.25, height=0.5)  
```


#### Grouping and summarizing rating across conditions and trait types

Aggregation step. 

```{r summarizing the data}
ms <- d.raw %>%
  group_by(condition, traitType) %>%
  summarize(mean = mean(rating), se =sem(rating))

```

#### Plot of average rating

```{r ggplot condition}
  
ggplot(ms,aes(x=condition,y=mean,fill=traitType))+  geom_bar(position='dodge',stat='identity') + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se),
                  width=.2,                    # Width of the error bars
                  position=position_dodge(.9)) + 
                  scale_fill_manual(values=c("#FF6633", "#33CCCC"))+
                 ylab("Average Rating") + 
                 ggtitle ("Rating of Trait Centrality to Creativity across Conditions") +
  theme_bw() 

```

###Confirmatory analysis
1. Mixed-moded analysis with condition as between subject and trait as within subject.

#### Main Data analysis: Mixed model ANOVA

#### Descriptive statistics: mean and se across conditions & trait types
```{r mean and standard deviation of rating across trait types and condition}
ms
```

```{r mixed model Anova: Main analyses}
# Mixed mode ANOVA with one between subject factor of condition and one within subject factor if trait type 
# One Within Factors W1, One Between Factors B1  
# fit <- aov(y~(W1*B1)+Error(Subject/(W1))+(B1),

fitConTrait <- aov(rating~(traitType*condition)+Error(workerid/(traitType))+(condition),
  	data=d.raw)
summary(fitConTrait)

# effect size
#etaSquared(fitConTrait, type=2, anova=F)
#etaSquared( fitConTrait, type = 2, anova = FALSE )
```

2. Two repeated measure ANOVA's for each condition to check the effect size of trait type in each condition

####Follow up data analyses: trait type rating within conditions
```{r first follow up: difference in rating of trait types in divergent condition}
#effect of trait types in Divergent condition: Within subject anova
# One Within Factor: fit <- aov(y~A+Error(Subject/A),data=mydataframe)
fitdivergent <- aov(rating [condition=='Divergent'] ~ traitType[condition=='Divergent'] + Error(workerid[condition=='Divergent']/traitType[condition=='Divergent']), data=d.raw)
summary(fitdivergent)
#effect size
cohen.d(d.raw$rating[d.raw$traitType=='Masculine' & d.raw$condition =='Divergent'],d.raw$rating[d.raw$traitType=='Feminine' & d.raw$condition =='Divergent'])
```


```{r second follow up: difference in rating of trait types in convergent condition }
#effect of trait types in Divergent condition: Within subject anova
# One Within Factor: fit <- aov(y~A+Error(Subject/A),data=mydataframe)
fitConvergent <- aov(rating [condition=='Convergent'] ~ traitType[condition=='Convergent'] + Error(workerid[condition=='Convergent']/traitType[condition=='Convergent']), data=d.raw)
summary(fitConvergent)
#effect size
cohen.d(d.raw$rating[d.raw$traitType=='Masculine' & d.raw$condition =='Convergent'],d.raw$rating[d.raw$traitType=='Feminine' & d.raw$condition =='Convergent'])
```

3. Two one-way ANOVA's for each trait to see the effect size of the condition.

####Follow up data analyses: trait type rating between conditions
```{r effect of condition on rating of the masculine trait types}
#masculine rating across conditions
# One Way Anova (Completely Randomized Design): fit <- aov(y ~ A, data=mydataframe)
fitMasculine<- aov(rating[traitType=='Masculine'] ~ condition[traitType=='Masculine'], data=d.raw)
summary(fitMasculine)
#effect size
fes(0.163, 2, 2)
cohen.d(d.raw$rating[d.raw$traitType=='Masculine' & d.raw$condition =='Divergent'],d.raw$rating[d.raw$traitType=='Masculine' & d.raw$condition =='Convergent'])
```

```{r effect of condition on rating of the feminine trait types}

#feminine rating across conditions
# One Way Anova (Completely Randomized Design): fit <- aov(y ~ A, data=mydataframe)
fitFeminine<- aov(rating[traitType=='Feminine'] ~ condition[traitType=='Feminine'], data=d.raw)
summary(fitFeminine)
# effect size
fes(0.43, 2, 2)
cohen.d(d.raw$rating[d.raw$traitType=='Feminine' & d.raw$condition =='Divergent'],d.raw$rating[d.raw$traitType=='Feminine' & d.raw$condition =='Convergent'])
```

###Exploratory analyses
Any follow-up analyses desired (not required).
1. Regression analysis including the gender and ethnicity of participants (mainly) as well as their income and education (potentially.)


####Exploratory analyses: mixed-model regression
```{r lmer}
#model with trait type and condition only
model1 <- lmer(rating~ traitType * condition + (1 +traitType | workerid), data=d.raw)
summary(model1)

#Model2 <- lmer(rating~ traitType + condition + ethnicity+ (1 +traitType | workerid), data=d.raw)
#summary(model2)

```
##Discussion

###Summary of Replication Attempt
Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

###Commentary
Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.

