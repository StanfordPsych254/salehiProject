---
title: 'Pilot Data Analyses for Gender Bias in the Attribution of Creativity'
author: "Shima Salehi"
date: "February 25, 2016"
output: 
  html_document:
    toc: true
---

Original experiment is [here](https://stanford.edu/~salehi/salehiProject/mockup3/creativity.html).

				
# Replication of Study A Gender Bias in the Attribution of Creativity: Archival and Experimental Evidence for the Perceived Association Between Masculinity and Creative Thinking 		

by 		
					
###Devon Proudfoot, Aaron C. Kay, and Christy Z. Koval 
				
###(2015, Psychological Science)

Shima Salehi
salehi@stanford.edu

##Contacting the authors

I have contacted the authors asking for the exclusion policy as well as their materials for the first study. Shortly, the authors replied in regard of exclusion policy and generously provided the survey of the first study on the Qualtrics platform. In the original study, they used no exclusion policy.

##Introduction

The goal of this study was to examine whether in terms of creativity men and their works would be evaluated differently than women and their works. In other words, whether the judgement of creativity is influenced by the gender of a creator. To test this hypothesis, the authors asked participants to rate creativity of stereotypically masculine characteristics as well as stereotypically feminine characteristics. The researchers compared whether the attribution of creativity varied significantly across gendered characteristics. Furthermore, authors were interested to speculate that given there might be a gender bias for attribution of creativity, this bias could be moderated by how creativity is defined. They used two different definitions for creativity: 1. divergent thinking: thinking outside the box, 2. convergent thinking: bringing pieces together and connecting the dots. They decided on these two definitions, because these definition are aligned with agency and communality divide, which has been associated with masculinity and femininity divide. Therefore, authors pursued whether by defining creativity as a communal and more feminine trait versus. a more agentic and masculine trait, they can manipulate the potential gender bias in attribution of creativity.

##Methods

###Power Analysis 
The power analysis is calculated based on two separate repeated measure anova analyses the authors have conducted for each of the two creativity definition condition.The effect size of centrality difference for the two trait types in the divergent condition (dd) is 1.25 and the same effect size in the convergent condition (dc) 0.94. Therefore, for convergent condition that dc=0.94 and p-value <0.001 the post-hoc power is 0.986 ~ 0.99. For divergent condition, on the other hand, with dd= 1.25 and same p-value the post-hoc power is 0.999 =1.

###Planned Sample
As for the divergent condition the power is 1, the planned sample size at the significance level of 0.01 will be 20. For convergent condition with the power of 0.99, for the same significance level of 0.01, the sample size will be 28 . Therefore, in total I will need 48 participants. With this sample size, the effect size will be 0.94 for convergent group and 1.21 for divergent group.

##Materials & Procedure
	
###Study1:
“Participants were randomly assigned to one of two conditions. Participants in the divergent-thinking condition read a passage describing creativity as the ability to “think outside the box,” see the world differently than the average person does, and create things that do not conform to traditions. Participants in the convergent-thinking condition read that creativity is the ability to “connect the dots,” see the connections between disparate ideas, and create things that bring ideas together in a unique way (see the Supplemental Material for the text used for this manipulation).
						
Participants then rated, on a 9-point scale, how central 16 personality traits were to creativity, as described in the passage. Eight of the traits were stereotypically masculine-agentic (decisive, competitive, self-reliant, willing to take risks, ambitious, daring, adventurous, courageous), and 8 were stereotypically feminine-communal (sensi- tive, cooperative, understanding of others, helpful to others, sympathetic, nurturing, warm in relations with others, and supportive; cf. Prentice & Carranza, 2002). An exploratory factor analysis with varimax rotation revealed a two-factor structure. The 8 masculine-agentic traits loaded onto one factor, so ratings of these traits were combined (α = .88). The 8 feminine-communal traits loaded onto the other factor, so ratings of these traits were combined (α = .92).”

##Analysis Plan

Same as the authors of the original paper, I am going to conduct “a mixed-model ANOVA with condition as the between-subjects factor and trait type as the within-subjects factor”. After that I will conduct two separate repeated measure ANOVA's for each of the creativity definitions to estimate the effect size of the trait type within each condition. Furthermore, for each group of gendered characteristics, we will compare the average creativity score across conditions. These are the confirmatory analyses.In addition to these, I will conduct some exploratory analysis. First I will check if manipulation check affect the results. This is more explained in data prep section and exploratory analyses section. Then, I will conduct a regression analysis to include other theoretically meaningful variables - ethnicity, education, and gender of participants- in analyzing the centrality rating of the traits for the creativity. Same as the authors, we are collecting data on age, gender, education, ethnicity, political orientation and income.

Furthermore, for manipulation check, besides the aim of the study included in the  original study, I have included a question about the definition of the creativity as a manipulation check for participants' paying attention to the provided definition of creativity.

##Differences from Original Study
There is no main planned difference from the original study. There are two minor differences: first, according to the power analysis the sample size will be smaller; second, instead of showing all the traits in one table the trait will be shown sequentially one at the time.

##Actual Sample
"In the original study, eighty participants (49% female, U.S. residents) were recruited from Amazon Mechanical Turk. Demographic variables did not moderate the results."" 


##Differences from pre-data collection methods plan
None.

##Pilot Samples
I have conducted a sample survey on the Mturk sandbox, and collected data from four pilot participants.  


##Results

###Data preparation
Turning json files per participants to one collective data frame with the variables of interest: rating of different traits, condition, gender, age, education, ethnicity, political orientation and income.

#### Loading Libraries
```{r loading library and fuction}
rm(list=ls())
library(tidyr)
library(dplyr)
library(ggplot2)
library(langcog) 
library(rjson)
library(tidyjson)
library(car)
library(effsize)
library(compute.es)
library(lme4)
library(lsr)

#functions for se and CI
sem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}
ci95 <- function(x) {sem(x) * 1.96}
```

####Transforming data from JSON format to dataframe
reading the JSON files and transform them to one dataframe.
```{r reading data from JSON files to dataframe}
path <- "~/Documents/Git/salehiProject/mturk/"
files <- dir(paste0(path,"sandbox-results/"), 
             pattern = "*.json")
d.raw <- data.frame()
for (f in files) {
  jf <- paste0(path, "sandbox-results/",f)
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  id <- data.frame(workerid = jd$WorkerId, 
                   trial_number_block=    as.factor(jd$answers$data$trial_number_block),
                   rating = as.numeric(jd$answers$data$rating),
                   gender = jd$answers$data$gender,
                   age = jd$answers$data$age,
                    sentence = jd$answers$data$sentence,
                    definition = jd$answers$data$definition,
                    political = jd$answers$data$political,
                    condition = as.factor(jd$answers$data$condition),
                    homelang = jd$answers$data$homelang,
                    income = jd$answers$data$income,
                    education = jd$answers$data$education,
                    ethnicity = jd$answers$data$ethnicity)

  d.raw <- bind_rows(d.raw, id)
}

# Number of participants
length(unique(d.raw$workerid))
```

####Categorizing Traits into "Masculine" and "Feminine"
To be able to test the effect of trait type (either masculine or feminine), in the following a categorical variable of 'traitType' has been defined with two levels of masculine and feminine.
```{r trait type variable}
#creating a bolean varible for traits which are masculine vs. feminine ones
d.raw $trait <- d.raw $ sentence =='Decisive' | d.raw $ sentence =='Competitive'| d.raw $ sentence =='Self-reliant' | d.raw $ sentence =='Willing to take risks' | d.raw $ sentence =='Ambitious'| d.raw $ sentence =='Daring' | d.raw $ sentence =='Adventurous' | d.raw $ sentence =='Courageous'

#creating a varible with masculine and feminine labels rather than True and False
d.raw $traitType <- ifelse(d.raw $trait == TRUE, "Masculine", "Feminine")

#checking if relabling work properly without mislabeling
table(d.raw $traitType,d.raw $trait )
table(d.raw$traitType, d.raw$sentence)
```


####Formating variables in dataframe
Adjusting the type of variables
```{r reformatting data}
##trait type
d.raw $traitType <- as.factor(d.raw $traitType)
##condition
d.raw $condition <- as.factor(d.raw $condition)
##gender
d.raw $gender <- as.factor (d.raw $gender)

##
d.raw$ageL <- as.numeric(factor(d.raw $age , levels=c("0-17","18-24", "25-34","35-44","45-64","&gt;65")))
d.raw $ageF <- as.factor (d.raw $age)

##education
#definiing ordinal variable both linear and caregorical
d.raw$educationL <- as.numeric(factor(d.raw $education , levels=c("someMiddleSchool" ,
          "someHighSchool", "highSchoolDrad","someCollege","collegeGraduate","someGrad","Grad")))
d.raw $educationF <- as.factor (d.raw $education)

##ethnicity
d.raw $ethnicityF <- as.factor(d.raw$ethnicity)
#definiing ordinal variable both linear and caregorical

##income
#definiing ordinal variable both linear and caregorical
d.raw$incomeL <- as.numeric(factor(d.raw $income , levels=c("LessThan15000" , "15000-24999", "25000-34999","35000-49999","50000-74999","75000-99999","100000-149999","150000-199999","morethan200000")))
d.raw $incomeF <- as.factor (d.raw $income)

##political orientation
#definiing ordinal variable both linear and caregorical
d.raw$politicalL <- as.numeric(d.raw $political)
d.raw $politicaF <- as.factor (d.raw $political)

```

Furthermore, I will code the two manipulation check variables: definition of creativity, and the aim of the study on the binary scale. For definition, I will code whether a participant's definition is aligned with the definition given in her condition. For the aim variable, there will be two levels: first, "no guess" meaning that the participant's guess about the purpose of the study is at most about creativity; second level is "close guess", when participants go beyond creativity and anticipate the study is looking at the variation of creativity across traits.

#### Manipulation check coding
```{r manipulation check}
##1. definition test
#if the participants' definition of creativit is aligned with the definition they are given in the condition. It has three levels: NA if they do not answer the question; 'aligned' if the their definition is aligned with the given defintion; 'not aligned' if their definition is not aligned with the given definition
d.raw$definitionTest[d.raw$workerid=='A1AL6BBWFSGZKI'] <- NA
d.raw$definitionTest[d.raw$workerid=='A35360IU4D4R7L'] <- "aligned"
d.raw$definitionTest[d.raw$workerid=='A1CBWFLUD10F23'] <- NA
d.raw$definitionTest[d.raw$workerid=='ALB9E1HP4FVN3'] <- "aligned"

##2. experiment test
#participants' guess about the goal of the study goes beyond creativity and mentioned more specific goal about the attribution of creativity to different traits
d.raw$expTest[d.raw$workerid=='A1AL6BBWFSGZKI'] <- "noGuess"
d.raw$expTest[d.raw$workerid=='A35360IU4D4R7L'] <- "closeGuess"
d.raw$expTest[d.raw$workerid=='A1CBWFLUD10F23'] <- NA
d.raw$expTest[d.raw$workerid=='ALB9E1HP4FVN3'] <- "closeGuess"
```
Given the few number of participants, it is difficult to use this manipulation check to detect any difference. However, for more number of participants, I hypothesized that the participants with close guess about the goal of the experiments or the one whose definitions are aligned with the definition of the activity might show the condition effect more.Therefore, in each condition the participants will be grouped according to this manipulation test, and tested whether there is a significant difference in rating between these groups


####Histogram of ratings across conditions and trait types
```{r histograms}
#rating vs. condition and traits
qplot(rating, data = d.raw, binwidth= 1, fill= traitType, facets = traitType ~ condition, geom = "histogram") +  scale_fill_manual(values=c("#FF6633", "#33CCCC")) +xlim(c(1,10))

#rating vs. condition and definition.test
#qplot(rating, data = d.raw, binwidth= 1, fill= traitType, facets = definitionTest ~ condition, geom = "histogram") +  scale_fill_manual(values=c("#FF6633", "#33CCCC")) +xlim(c(1,10))

#rating vs. condition and definition.test
#qplot(rating, data = d.raw, binwidth= 1, fill= traitType, facets = aimTest ~ condition, geom = "histogram") +  scale_fill_manual(values=c("#FF6633", "#33CCCC")) +xlim(c(1,10))

# the two histogram for manipulation check would stop knitting process, as there is NA, and there is no participants for one level of each variables in this sample.

```

#### ggplot with geompoint
```{r ratings of trattypes across condition}
ggplot(d.raw, aes(x = condition, y = rating, col = traitType)) + 
  geom_jitter(width=0.25, height=0.5) +
  scale_colour_manual(values=c("#FF6633", "#33CCCC"))
```
This plot suggest that all ratings have slightly shifted downward slightly in the convergent type, regardless of a trait type. This pattern was hinted also in the original paper.

#### Grouping and summarizing rating across conditions and trait types
In the following, the mean and standard error or rating has been calculated across condition and trait types.

```{r summarizing the data}
#including trait type and condition in grouping
ms1 <- d.raw %>%
  group_by(condition, traitType) %>%
  summarize(mean = mean(rating), se =sem(rating))
```
This data has been plotted in the follwoing graph.

#### Plot of average rating
```{r ggplot condition}
  
ggplot(ms1,aes(x=condition,y=mean,fill=traitType))+  geom_bar(position='dodge',stat='identity') + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se),
                  width=.2,                    # Width of the error bars
                  position=position_dodge(.9)) + 
                  scale_fill_manual(values=c("#FF6633", "#33CCCC"))+
                 ylab("average Rating") + 
                 ggtitle ("Rating of Trait Centrality to Creativity across Conditions") +
  theme_bw() 
```
Same as the data pattern in the original paper, masculine traits in both conditions have been rated more central to creativity. Furthermore, in convergent condition the overall ratings have decreased for both masculine and feminine traits. This was also observed in the original paper.


###Confirmatory analysis
1. Mixed-moded analysis with condition as between subject and trait as within subject.

#### Main Data analysis: Mixed model ANOVA

#### Descriptive statistics: mean and se across conditions & trait types
```{r mean and standard deviation of rating across trait types and condition}
ms1
```
According to the analyses in the original paper, there has been conducted a mixed-mode ANOVA with condition as between subject factor and trait types as within subject factor.
```{r mixed model Anova: Main analyses}
# Mixed mode ANOVA with one between subject factor of condition and one within subject factor if trait type 
# One Within Factors W1, One Between Factors B1  
# fit <- aov(y~(W1*B1)+Error(Subject/(W1))+(B1),

fitConTrait <- aov(rating~(traitType*condition)+Error(workerid/(traitType))+(condition),
  	data=d.raw)
summary(fitConTrait)

# effect size
#I could not find any code for calculating the effect size of mixed model ANOVA in R onlt the following two suggested in stack over flow blogs, which are not functional
#etaSquared(fitConTrait, type=2, anova=F)
etaSquared( fitConTrait, type = 2, anova = FALSE )
```
There is a main effect of trait type; F(1,2)=57.80, p-value = 0.017, ηp2=??. However, the interaction of trait type and condition is not significant. 
The significant main effect of trait type was also observed in the original study. However, in that study, there also existed a marginal interaction effect of trait type and condition that it is not observed here, which could be due to the very small sample size of this pilot study.

2. Two repeated measure ANOVA's for each condition to check the effect size of trait type in each condition

The author did two sets of follow-up studies: first, repeated measure ANOVA for the effect of trait type within conditions; second, one-way ANOVA for the effect of condition on the rating of a particular trait type (i.e masculine or feminine). These follow up tests have been repeated in the following.

####Follow up data analyses: trait type rating within conditions
```{r first follow up: difference in rating of trait types in divergent condition}
#effect of trait types in Divergent condition: Within subject anova
# One Within Factor: fit <- aov(y~A+Error(Subject/A),data=mydataframe)
fitdivergent <- aov(rating [condition=='Divergent'] ~ traitType[condition=='Divergent'] + Error(workerid[condition=='Divergent']/traitType[condition=='Divergent']), data=d.raw)
summary(fitdivergent)
#effect size
cohen.d(d.raw$rating[d.raw$traitType=='Masculine' & d.raw$condition =='Divergent'],d.raw$rating[d.raw$traitType=='Feminine' & d.raw$condition =='Divergent'])
```


```{r second follow up: difference in rating of trait types in convergent condition }
#effect of trait types in Divergent condition: Within subject anova
# One Within Factor: fit <- aov(y~A+Error(Subject/A),data=mydataframe)
fitConvergent <- aov(rating [condition=='Convergent'] ~ traitType[condition=='Convergent'] + Error(workerid[condition=='Convergent']/traitType[condition=='Convergent']), data=d.raw)
summary(fitConvergent)
#effect size
cohen.d(d.raw$rating[d.raw$traitType=='Masculine' & d.raw$condition =='Convergent'],d.raw$rating[d.raw$traitType=='Feminine' & d.raw$condition =='Convergent'])
```
These follow up tests show that although for both conditions the direction of data is aligned with the original study, masculine traits being rated more central to creativity in both conditions, they do not reach significant level: For divergent condition: (M= 6.48, SD= 0.63; vs. M= 4.88, SD=0.43), F(1, 2)= 69.44 , p = 0.076 , d= 0.73 ; and for convergent condition: (M= 6.13, SD= 0.46; vs. M= 4.5, SD=0.38), F(1, 2)= 18.78 , p = 0.144, d=0.97.

The lack of significance could be again attributed to the small sample size in the pilot study.


3. Two one-way ANOVA's for each trait to see the effect size of the condition.
The second set of follow up tests that were conducted in the original study was one-way ANOVA's to examine the effect of condition on rating of a particular trait types.
####Follow up data analyses: trait type rating between conditions
```{r effect of condition on rating of the masculine trait types}
#masculine rating across conditions
# One Way Anova (Completely Randomized Design): fit <- aov(y~A+Error(Subject/A),data=mydataframe)


fitMasculine<- aov(rating[traitType=='Masculine']~condition[traitType=='Masculine'], data=d.raw)
summary(fitMasculine)

#The correct anova should be this, but this is not working.
#fitMasculine<- aov(rating[traitType=='Masculine']~condition[traitType=='Masculine']+Error(workerid[traitType=='Masculine']/condition[traitType=='Masculine']), data=d.raw)

#effect size
cohen.d(d.raw$rating[d.raw$traitType=='Masculine' & d.raw$condition =='Divergent'],d.raw$rating[d.raw$traitType=='Masculine' & d.raw$condition =='Convergent'])
```
Unlike the original study, condition had no effect on rating of masculine traits, F(1,30) = 0.163 , p=0.689, d = 0.14. This implies that the conception of creativity does not affect how central participants perceive a trait to creativity.


```{r effect of condition on rating of the feminine trait types}

#feminine rating across conditions
# One Way Anova (Completely Randomized Design): fit <- aov(y~A+Error(Subject/A),data=mydataframe)
fitFeminine<- aov(rating[traitType=='Feminine'] ~ condition[traitType=='Feminine'], data=d.raw)
summary(fitFeminine)

## Again, the currect anova is the following. Howver, it gave me the error "Error() model is singular", which I beleive is due to the samll number of participants and small df.

#fitFeminine2<- aov(rating[traitType=='Feminine'] ~ condition[traitType=='Feminine']+ Error(workerid[traitType=='Feminine']/condition[traitType=='Feminine']), data=d.raw)
#summary(fitFeminine2)

# effect size
cohen.d(d.raw$rating[d.raw$traitType=='Feminine' & d.raw$condition =='Divergent'],d.raw$rating[d.raw$traitType=='Feminine' & d.raw$condition =='Convergent'])
```
Similar to masculine traits, it is observed that condition does not effect the rating of feminine traits, F(1, 30)= 0.43, p-value= 0.52, d=0.23. Again it seems that the definition of creativity does not effect how central participants find the feminine traits to creativity.

As I mentioned above for the second type of follow up tests, I believe I am running the wrong type of ANOVA. However, I cannot run the more accurate one as I will limit df by counting for within subject of variation and will face the overspecification of my model

###Exploratory analyses
Any follow-up analyses desired (not required).


1. examining the effect of manipulation checks

#### Averaging the rating across condition and trait type as well as manipulation check variables

```{r adding the manipulation check variables to grouping criteria }

ms.man <- d.raw %>% 
  group_by(condition, traitType,definitionTest, expTest ) %>%
  summarize(mean = mean(rating), se =sem(rating))

# I did not omit NA's here, as if I had done so there would be no facet in the graph. So for bettershow of concet, I kept NA's in the data, although it is an odd choice.
```

#### Plot of average rating with manipulation check
the same bar ggplot that we had for confirmatory analyses, however this time facet across two manipulation check variables. To compare if the extent of paying attention to the definition of creativity (definitionTest) and their understanding about the goal of study would effect the effect of manipulation.
```{r ggplot condition with manipulation check}
  
ggplot(ms.man,aes(x=condition,y=mean,fill=traitType))+  geom_bar(position='dodge',stat='identity') + 
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se),
                  width=.2,                    # Width of the error bars
                  position=position_dodge(.9)) +
                  facet_grid(definitionTest~expTest)+
                  scale_fill_manual(values=c("#FF6633", "#33CCCC"))+
                  ylab("average Rating") + 
                  ggtitle ("Rating of Trait Centrality to Creativity ") +
  theme_bw()

```

I cannot do the following  analyses with this subset of participants; however, in the actual data in case that there was a difference in the facets of the above graph, I plan to subset the data for the participants who have the definition "aligned" with the definition offered to them, but they could not have a close guess of the study purpose to see if we can see the effect of trait type for this group, as well.

```{r subsetting according to the manipulation check}
                  
d.man <- subset(d.raw, definitionTest=='aligned' & expTest=='noGuess') 
#this is going to be an empty data set for this data      
```        

```{r repeating the analyses for the subset data}
                  
#fitConTrait.man <- aov(rating~(traitType*condition)+Error(workerid/(traitType))+(condition),data=d.man)
#summary(fitConTrait.man )
                  
```                  
2. Regression analysis including the gender and ethnicity of participants (mainly) as well as their income and education (potentially.)

I would like to include eduction, ethnicity, and gender of participants in my analyses to 


####Exploratory analyses: mixed-model regression
```{r lmer basic}
#model with trait type and condition only
model1 <- lmer(rating~ traitType * condition + (1 +traitType | workerid), data=d.raw)
summary(model1)
```


```{r lmer including gender}

#this model will not work, because I only have male participants in my data.
#model2 <- lmer(rating~ traitType * condition + gender + (1 +traitType | workerid), data=d.raw)
#summary(model2)

```


```{r lmer including education level}
model3 <- lmer(rating~ traitType * condition + educationF+ (1 +traitType | workerid), data=d.raw)
summary(model3)
```


```{r lmer including both education and ethnicity}
model4 <- lmer(rating~ traitType * condition + educationF+ ethnicityF+ (1 +traitType | workerid), data=d.raw)
summary(model4)
```


```{r lmer including education, ethnicity, and gender}
# the complete model that I would like to test in bottom-up step wise manner is the following that I cannot run due to having a single-gender participants.

#model5 <- lmer(rating~ traitType * condition + educationF+ ethnicityF+ gender + (1 +traitType | workerid), data=d.raw)
#summary(model5)
```
In all the above models, trait type and condition have the highest t values. Also, except for basic model, for the other models, condition has a higher t value than the trait type.
In none of the above models, there exists any significant IV, as the sample is very small. Also, therefore, given this pilot data I believe comparing the fit of these models are not really meaningful.As a result, I cannot make the model more complex in stepwise fashion. However, with a larger sample, to the basic lmer, I will first add the gender of participants and check if this addition improves the model fit significantly. I will repeat this for education and ethnicity. the reason for these tests is the hypothesis that gender of the participants, their education, or ethnicity might affect their gender bias in attributing creativity.


##Discussion

###Summary of Replication Attempt

Same as the original paper, there was a main effect of the trait type on rating of centrality of the trait to the creativity. In other words, regardless of the definition of creativity used in each condition, participants rate masculine traits more central to creativity. Same as the original studies, for both definitions of creativity, the masculine traits were rated higher than feminine traits in regard to creativity, although, unlike the original study, these differences did not reach significance level due to a small sample size.

Unlike the original study, in this sample there was no marginal interaction effect between condition and trait type. This implies changing the definition of creativity does not affect to what extent participants find masculine traits more central to creativity rather than feminine traits. This was confirmed by the second set of follow up tests that showed the rating of trait types did not change across conditions. 

Overall, this pilot study replicates the original paper finding that individuals find masculine traits more central to creativity. However, unlike the original study, this pilot shows that changing the definition of creativity does not attune this gender bias, whereas in the original study using convergent definition for creativity decreased the gender bias and the difference in centrality of feminine vs. masculine traits to creativity. 

The absence of interaction between condition and trait type in this pilot could be attributed to the noticeably small sample size. In fact, observing the main effect of trait type even with this small sample size, four participants, is very astonishing.

###Commentary
None could be added in this version. As it was not possible to fully conduct the exploratory analyses.

